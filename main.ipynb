{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "data['Amount']=sc.fit_transform(pd.DataFrame(data[\"Amount\"]))\n",
    "# here we are changing the range of amount from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppin the time column as we dont need it\n",
    "data=data.drop([\"Time\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Amount'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data[\"Amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(\"Class\",axis=1)\n",
    "y=data[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========LogisticRegression===========\n",
      "Accuracy Score : 0.9992200678359603\n",
      "Precision Score : 0.8870967741935484\n",
      "Recall Score : 0.6043956043956044\n",
      "F1 Score : 0.718954248366013\n",
      "\n",
      "==========DecisionTreeClassifier===========\n",
      "Accuracy Score : 0.9990024123483213\n",
      "Precision Score : 0.6914893617021277\n",
      "Recall Score : 0.7142857142857143\n",
      "F1 Score : 0.7027027027027027\n"
     ]
    }
   ],
   "source": [
    "classifier={\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\":DecisionTreeClassifier()\n",
    "}\n",
    "for name,clf in classifier.items():\n",
    "  print(f\"\\n=========={name}===========\")\n",
    "  clf.fit(X_train,y_train)\n",
    "  y_pred=clf.predict(X_test)\n",
    "  print(f\"Accuracy Score : {accuracy_score(y_test,y_pred)}\")\n",
    "  print(f\"Precision Score : {precision_score(y_test,y_pred)}\")\n",
    "  print(f\"Recall Score : {recall_score(y_test,y_pred)}\")\n",
    "  print(f\"F1 Score : {f1_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will undersample the normal samples\n",
    "normal=data[data[\"Class\"]==0]\n",
    "fraud=data[data[\"Class\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal=normal.sample(473)\n",
    "# Here we have undersampled the normal transaction to the level \n",
    "# of fraud data and now again we will do the above operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=pd.concat([normal,fraud],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=new_data.drop(\"Class\",axis=1)\n",
    "y=new_data[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========LogisticRegression===========\n",
      "Accuracy Score : 0.9421052631578948\n",
      "Precision Score : 0.9690721649484536\n",
      "Recall Score : 0.9215686274509803\n",
      "F1 Score : 0.9447236180904522\n",
      "\n",
      "==========DecisionTreeClassifier===========\n",
      "Accuracy Score : 0.9157894736842105\n",
      "Precision Score : 0.9215686274509803\n",
      "Recall Score : 0.9215686274509803\n",
      "F1 Score : 0.9215686274509803\n"
     ]
    }
   ],
   "source": [
    "classifier={\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\":DecisionTreeClassifier()\n",
    "}\n",
    "for name,clf in classifier.items():\n",
    "  print(f\"\\n=========={name}===========\")\n",
    "  clf.fit(X_train,y_train)\n",
    "  y_pred=clf.predict(X_test)\n",
    "  print(f\"Accuracy Score : {accuracy_score(y_test,y_pred)}\")\n",
    "  print(f\"Precision Score : {precision_score(y_test,y_pred)}\")\n",
    "  print(f\"Recall Score : {recall_score(y_test,y_pred)}\")\n",
    "  print(f\"F1 Score : {f1_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we can see undersampling the data we have got a better precision recall and f1 score. \n",
    "# So it is better to undersample or oversample the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERSAMPLING\n",
    "X=data.drop([\"Class\"],axis=1)\n",
    "y=data[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1    275190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_res,y_res=SMOTE().fit_resample(X,y)\n",
    "y_res.value_counts()\n",
    "# Smote will add data points in between the data which is less \n",
    "# and make it equal to the larger class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_res,y_res,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========LogisticRegression===========\n",
      "Accuracy Score : 0.9434118245575784\n",
      "Precision Score : 0.9729829325058185\n",
      "Recall Score : 0.9120775230441975\n",
      "F1 Score : 0.9415463153252066\n",
      "\n",
      "==========DecisionTreeClassifier===========\n",
      "Accuracy Score : 0.9982830044696391\n",
      "Precision Score : 0.9976214685162321\n",
      "Recall Score : 0.9989455120629784\n",
      "F1 Score : 0.9982830512631837\n"
     ]
    }
   ],
   "source": [
    "classifier={\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\":DecisionTreeClassifier()\n",
    "}\n",
    "for name,clf in classifier.items():\n",
    "  print(f\"\\n=========={name}===========\")\n",
    "  clf.fit(X_train,y_train)\n",
    "  y_pred=clf.predict(X_test)\n",
    "  print(f\"Accuracy Score : {accuracy_score(y_test,y_pred)}\")\n",
    "  print(f\"Precision Score : {precision_score(y_test,y_pred)}\")\n",
    "  print(f\"Recall Score : {recall_score(y_test,y_pred)}\")\n",
    "  print(f\"F1 Score : {f1_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(X_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credit_card_predict.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(dtc,\"credit_card_predict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=joblib.load(\"credit_card_predict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaibh\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict([[1.19185711131486,0.26615071205963,0.16648011335321,0.448154078460911,0.0600176492822243,-0.0823608088155687,-0.0788029833323113,0.0851016549148104,-0.255425128109186,-0.166974414004614,1.61272666105479,1.06523531137287,0.48909501589608,-0.143772296441519,0.635558093258208,0.463917041022171,-0.114804663102346,-0.183361270123994,-0.145783041325259,-0.0690831352230203,-0.225775248033138,-0.638671952771851,0.101288021253234,-0.339846475529127,0.167170404418143,0.125894532368176,-0.00898309914322813,0.0147241691924927,2.69]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]\n",
    "# as we can see we got our class as 0 which has been correctly predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal transaction\n"
     ]
    }
   ],
   "source": [
    "if pred==0:\n",
    "    print(\"Normal transaction\")\n",
    "else:\n",
    "    print(\"Fraud Transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
